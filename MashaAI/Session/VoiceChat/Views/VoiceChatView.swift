import ElevenLabsSDK
import SwiftUI

// ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ð°Ñ Ð¾ÑÐ½Ð¾Ð²Ð½Ð°Ñ View
struct VoiceChatView: View {

    @ObservedObject
    var viewModel: VoiceChatVM

    var body: some View {
        VStack {
            ZStack {
                LinearGradient(
                    stops: .voiceChatBackground,
                    startPoint: .top,
                    endPoint: .bottom
                )
                .mask {
                    Circle()
                        .fill(.white)
                        .blur(radius: 40)
                        .frame(width: 400)
                        .offset(y: 50)
                }
                .animateAppear(.optionButton(delay: 0.8))

                Image(.masha)
                    .resizable()
                    .scaledToFill()
                    .frame(width: 300, height: 400)
                    .animateAppear(.optionButton(delay: 0.8))
            }
            .padding(.bottom, 180)
        }
        .frame(maxWidth: .infinity, maxHeight: .infinity, alignment: .bottom)
        .overlay(alignment: .bottom, content: bottomView)
        .background {
            Image(.voiceBackground)
                .resizable()
                .scaledToFill()
                .edgesIgnoringSafeArea(.all)
        }
        .overlay(alignment: .top, content: alertView)
        .onReceive(viewModel.$lastError) { error in
            guard error != nil else { return }

            DispatchQueue.main.asyncAfter(deadline: .now() + 5) {
                viewModel.viewState = .loading
            }
        }
        .onReceive(viewModel.$isAISpeaking) { isSpeaking in
            
        }
        .onDisappear {
            print("ðŸƒâ€â™‚ï¸ View disappearing, cleaning up...")
            viewModel.stopConversation()
        }
        .onAppear {
//            // Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ callbacks Ð´Ð»Ñ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ Ñ€ÐµÑ‡Ð¸ AI
//            viewModel.onAIStartedSpeaking = {
//                print("ðŸŽ¬ UI: AI started speaking!")
//                // Ð—Ð´ÐµÑÑŒ Ð¼Ð¾Ð¶Ð½Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð°Ð½Ð¸Ð¼Ð°Ñ†Ð¸Ð¸ Ð¸Ð»Ð¸ Ð´Ñ€ÑƒÐ³Ð¸Ðµ UI ÑÑ„Ñ„ÐµÐºÑ‚Ñ‹
//            }
//
//            viewModel.onAIStoppedSpeaking = { duration in
//                print("ðŸŽ¬ UI: AI stopped speaking! Duration: \(duration) seconds")
//                // Ð—Ð´ÐµÑÑŒ Ð¼Ð¾Ð¶Ð½Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð°Ð½Ð¸Ð¼Ð°Ñ†Ð¸Ð¸ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ Ñ€ÐµÑ‡Ð¸
//            }
        }
    }

    @ViewBuilder
    private func bottomView() -> some View {
        VStack(spacing: 24) {
            indicatorView()

            Button {
                handleButtonAction()
            } label: {
                actionButton()
            }
            .buttonStyle(.plain)
            .animateAppear(.optionButton(delay: 0.4))
        }
        .frame(maxWidth: .infinity, alignment: .bottom)
        .frame(height: 280)
        .background {
            Image(.voiceBottom)
                .resizable()
                .scaledToFill()
                .frame(height: 300)
                .offset(y: 15)
        }
        .animateAppear(.optionButton(delay: 0.4))
    }

    @ViewBuilder
    private func indicatorView() -> some View {
        ZStack {
            Text("ÐŸÑ€Ð¸Ð²ÐµÑ‚ Ñ ÐœÐ°ÑˆÐ°,\n Ð´Ð°Ð²Ð°Ð¹ Ð½Ð°Ñ‡Ð½ÐµÐ¼ Ð¸Ð³Ñ€Ð°Ñ‚ÑŒ")
                .typography(.M1.bold)
                .foregroundStyle(.white)
                .multilineTextAlignment(.center)
                .scaleEffect(viewModel.viewState == .connected ? 0.7 : 1.0)
                .opacity(viewModel.viewState == .connected ? 0.0 : 1.0)
                .animation(.easeInOut(duration: 0.3), value: viewModel.viewState)

            VStack(spacing: 12) {
                OrbView(
                    mode: viewModel.mode,
                    audioLevel: viewModel.audioLevel,
                    isAISpeaking: viewModel.isAISpeaking
                )
                .frame(width: 90, height: 90)
                // Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð°Ð½Ð¸Ð¼Ð°Ñ†Ð¸Ñ Ð¿Ñ€Ð¸ Ñ€ÐµÑ‡Ð¸ AI
                .scaleEffect(viewModel.isAISpeaking ? 1.2 : 1.0)
                .animation(.easeInOut(duration: 0.3), value: viewModel.isAISpeaking)

                // Ð¡Ñ‚Ð°Ñ‚ÑƒÑ AI
                Text(statusText)
                    .typography(.M1.regular)
                    .foregroundStyle(statusColor)
                    .multilineTextAlignment(.center)
                    .animation(.easeInOut(duration: 0.3), value: viewModel.isAISpeaking)
            }
            .scaleEffect(viewModel.viewState == .connected ? 1.0 : 0.7)
            .opacity(viewModel.viewState == .connected ? 1.0 : 0.0)
            .animation(
                .easeInOut(duration: 0.3).delay(viewModel.viewState == .connected ? 0.15 : 0.0),
                value: viewModel.viewState
            )
        }
    }

    private var statusText: String {
        if viewModel.isAISpeaking {
            return "ðŸ—£ï¸ ÐœÐ°ÑˆÐ° Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚..."
        } else {
            switch viewModel.mode {
            case .listening:
                return "ðŸ‘‚ ÐœÐ°ÑˆÐ° ÑÐ»ÑƒÑˆÐ°ÐµÑ‚"
            case .speaking:
                return "ðŸŽ¤ Ð“Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚Ðµ"
            }
        }
    }

    private var statusColor: Color {
        if viewModel.isAISpeaking {
            return .green
        } else {
            switch viewModel.mode {
            case .listening:
                return .blue
            case .speaking:
                return .orange
            }
        }
    }

    @ViewBuilder
    private func alertView() -> some View {
        if case .error = viewModel.viewState {
            VStack {
                Image(.alert)
                    .resizable()
                    .scaledToFill()
                    .frame(width: 280, height: 93)
            }
            .animateAppear(.alertAppear(delay: 0.1))
        }
    }

    private func handleButtonAction() {
        switch viewModel.viewState {
        case .loading, .error:
            viewModel.beginConversation()
        case .connected:
            viewModel.stopConversation()
        }
    }

    @ViewBuilder
    private func actionButton() -> some View {
        ZStack {
            // Start Button
            Image(.startButton)
                .resizable()
                .scaledToFit()
                .frame(width: 202, height: 105)
                .scaleEffect(viewModel.viewState == .connected ? 0.7 : 1.0)
                .opacity(viewModel.viewState == .connected ? 0.0 : 1.0)
                .animation(.easeInOut(duration: 0.3), value: viewModel.viewState)

            // Stop Button
            Image(.stopButton)
                .resizable()
                .scaledToFit()
                .frame(width: 202, height: 105)
                .scaleEffect(viewModel.viewState == .connected ? 1.0 : 0.7)
                .opacity(viewModel.viewState == .connected ? 1.0 : 0.0)
                .animation(
                    .easeInOut(duration: 0.3).delay(viewModel.viewState == .connected ? 0.15 : 0.0),
                    value: viewModel.viewState)
        }
    }
}

#Preview {
    VoiceChatView(viewModel: .init())
}
